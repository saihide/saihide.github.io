# cpu cache

CPU的处理速度和内存的访问速度差距越来越大，甚至可以达到上万倍。这种情况下传统的CPU通过FSB直连内存的方式显然就会因为内存访问的等待，导致计算资源大量闲置，降低CPU整体吞吐量。同时又由于内存数据访问的热点集中性，在CPU和内存之间用较为快速而成本较高的SDRAM做一层缓存，就显得性价比极高了。

![](https://saihide.github.io/image/4AA9AFAD-FDC4-4DB3-8F82-60BD0B6F0D0B.png)

下面一张图可以看出各级缓存之间的响应时间差距，以及内存到底有多慢！

![](https://saihide.github.io/image/C5C18845-173C-43CB-9466-8C1A7600CABE.png)

## 存储器层次结构

对于k层的存储设备作为位于k+1层的存储设备的缓存。层次结构中的每一层都缓存来自较低一层的数据对象.

![](https://saihide.github.io/image/6B173878-C7E1-41E2-9205-3C0A23BBD7CE.png)

### 存储器层次结构中的缓存

![](https://saihide.github.io/image/D8D75F7E-6233-46EB-B0C7-E998FC678D63.png)

冲突不命中：k+1层的块0，4，8，12都映射到k层的块1，如果先请求块0，然后块8，然后块0，然后块8，依此类推，在k层的缓存中，对这两个快的每次引用都会不命中

![](https://saihide.github.io/image/AF956FEB-C585-4AF7-9985-A22BDDB8B922.png)

### 高速缓存存储器：
每个存储器的地址有m位，高速缓存被组织成S个高速缓存组，每个组包含E个高速缓存行，每行由一个B字节的数据块，一个有效位指明这个行是否包含有意义的信息。还有t个标记位(是当前块的内存地址的位的一个子集)，它们唯一标识存储在这个高速缓存行中的块。高速缓存的结构用元组(S,E,B,m)来描述。高速缓存的大小C指的是所有块的大小的和，标记位和有效位不包括在内。C=S* E* B。

![](https://saihide.github.io/image/C9BD4D68-A52D-41CD-BEB2-C410B4E8CB6E.png)

![](https://saihide.github.io/image/6D0F4939-0A05-447C-BBE0-D0773AF93834.png)

#### 组相连高速缓存：

![](https://saihide.github.io/image/9A0F42D7-A7AD-4057-A536-553B7335C862.png)

组中的任何一行都可以包含任何映射到这个组的内存块。搜索组中的每一行，寻找一个有效的行，标记与地址中的标记想匹配，从偏移块中选择一个字。读一个字w，w的地址中取s个组索引位，选择组i，选择有效行，比较行中的标记与w地址中的标记相匹配，取w地址的b位，确定块偏移位是100，所以w的副本是从块中的第四字节开始的(假设字长位4字节)如果缓存不命中，需要从下一层取出被请求的块，然后将新的块存储在组索引位指示的组中的一个高速缓存行。如果组中都是有效高速缓存行了，就逐出一个现存的行。替换策略有随机选择，最不常使用LFU(在过去某个时间里引用次数最少的)，最近最少使用LRU(最后一次访问时间最久远的)

![](https://saihide.github.io/image/D9C5F3D6-17C9-4855-BAEF-21A5A4EF35B2.png)

#### 关于写的问题
假设要写一个已经缓存了的字w(写命中)，高速缓存更新了它的w副本之后，怎么更新w在低一层中的副本呢。

* 直写(write-through)：立即写到低一层，缺点是每次写都会引起总线流量
* 写回(write-back): 尽可能推迟更新，只有当替换算法要驱逐这个更新过的块时。缺点是增加了复杂性，每个cache line要额外维护一个修改位。
* 写分配(write-allocate): 写不命中时，加载低一层的块到高速缓存中，然后更新这个高速缓存快
* 非写分配(not-write-allocat)：避开高速缓存，直接写到低一层
通常是直写和非写分配，写回和写分配。

#### Intel Core i7 高速缓存层次结构解剖
 高速缓存既保存数据，也保存指令。只保存指令的高速缓存称为i-cache。只保存程序数据的高速缓存称为d-cache。既保存指令又保存数据的高速缓存称为统一的高速缓存(unified cache)。有两个独立的高速缓存，处理器能够同时读一个指令字和一个数据字，i-cache通常是只读的，因此比较简单。使用不同的高速缓存也确保了数据访问不会与指令访问形成冲突不命中，代价是可能会引起容量不命中增加。
 
 ![](https://saihide.github.io/image/74070C6C-2E3E-45AA-9145-C64348B845E9.png)
 
 ![](https://saihide.github.io/image/BF1F8704-A36A-4A72-8F3D-7CEBB7E69DB0.png)
 
####  高速缓存参数的性能影响

指标：

* 不命中率：在一个程序执行或程序的一部分执行期间，内存引用不命中的比率。不命中数量/引用数量
* 命中率：命中的内存引用比率。1-不命中率。
* 命中时间：从高速缓存传送一个字到CPU所需的时间，包括组选择，行确认和字选择的时间。对于L1高速缓存来说，命中时间的数量级是几个时钟周期。
* 不命中处罚：由于不命中所需要的额外的时间。L1不命中需要从L2得到的处罚，通常是10个周期，从L3得到的的处罚是50个周期，主存是200个周期。
   
影响：
     
* 高速缓存大小的影响：较大的高速缓存可能会提高命中率，可能会增加命中时间。
* 块大小的影响：
* 较大的块能利用程序中的空间局部性，不过，对于给定的高速缓存大小，块越大就意味着高速缓存行数越少，这回损害时间局部性比空间局部性更好的程序的命中率。较大的块对不命中处罚也有负面影响，因为块越大，传送时间就越长。
* 相联度的影响：
* 写策略的影响：








	